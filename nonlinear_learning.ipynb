{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from torcheval.metrics import BinaryConfusionMatrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomDataframe(samples,features,func,normal=False):\n",
    "    x =torch.rand([samples,features+1])\n",
    "    y=torch.where( func(x[:,:-1]) ,1,0)\n",
    "    if normal:            \n",
    "        x=x[~ y.bool()]\n",
    "        samples=x.shape[0]\n",
    "        x[:,-1]=0\n",
    "    else:\n",
    "        x[:,-1]=y\n",
    "    print(x[:,-1].mean())\n",
    "    print(samples,y.shape)\n",
    "    df=pd.DataFrame(x)\n",
    "    l=[f\"col_{i}\" for i in range(features)]\n",
    "    l.append(\"attack\")\n",
    "    df.columns=l\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NonLinear(x:torch.Tensor):\n",
    "    return (x[:, 0]**2+x[:, -1]**2-x[:, 0] * x[:, -1])>.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "8462 torch.Size([10000])\n",
      "tensor(0.1479)\n",
      "10000 torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "samples=10000\n",
    "features=5\n",
    "\n",
    "noraml_df=CustomDataframe(samples,features,NonLinear,True)\n",
    "abnoraml_df=CustomDataframe(samples,features,NonLinear,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECESION TREE\n",
    "works great here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=32)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier(random_state=32)\n",
    "df=abnoraml_df.copy(deep=True)\n",
    "y=df['attack']\n",
    "df.drop(columns=['attack'])\n",
    "dt.fit(X=df,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "col_0",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "col_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "col_2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "col_3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "col_4",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "72e0a645-bcfa-4fcf-9291-ab260774c073",
       "rows": [
        [
         "0",
         "0.7331781",
         "0.6955526",
         "0.63343495",
         "0.50065625",
         "0.7372024"
        ],
        [
         "1",
         "0.38788486",
         "0.26369447",
         "0.82197624",
         "0.7712815",
         "0.6862806"
        ],
        [
         "2",
         "0.106233716",
         "0.41898173",
         "0.83412904",
         "0.09900421",
         "0.031416893"
        ],
        [
         "3",
         "0.42707545",
         "0.9950367",
         "0.04640311",
         "0.96415156",
         "0.032464743"
        ],
        [
         "4",
         "0.34696865",
         "0.83512276",
         "0.08433032",
         "0.9503862",
         "0.6691542"
        ],
        [
         "5",
         "0.41191047",
         "0.31230408",
         "0.45231664",
         "0.7285451",
         "0.11027777"
        ],
        [
         "6",
         "0.28900254",
         "0.45728385",
         "0.1417355",
         "0.66252327",
         "0.37595224"
        ],
        [
         "7",
         "0.56450355",
         "0.77843004",
         "0.42532992",
         "0.6989266",
         "0.8067285"
        ],
        [
         "8",
         "0.5817278",
         "0.4895091",
         "0.70848995",
         "0.69519174",
         "0.033729613"
        ],
        [
         "9",
         "0.8018862",
         "0.38375926",
         "0.4068126",
         "0.44655025",
         "0.50304025"
        ],
        [
         "10",
         "0.45851493",
         "0.34445077",
         "0.5396887",
         "0.16170353",
         "0.015103936"
        ],
        [
         "11",
         "0.7828575",
         "0.061633408",
         "0.16445047",
         "0.36871254",
         "0.37287813"
        ],
        [
         "12",
         "0.9025932",
         "0.56495476",
         "0.6351674",
         "0.69080025",
         "0.6953556"
        ],
        [
         "13",
         "0.27868402",
         "0.59758323",
         "0.5976702",
         "0.15588444",
         "0.6104167"
        ],
        [
         "14",
         "0.8242915",
         "0.7096737",
         "0.07635492",
         "0.93520856",
         "0.32890213"
        ],
        [
         "15",
         "0.29258156",
         "0.91890186",
         "0.6856501",
         "0.3304456",
         "0.4890024"
        ],
        [
         "16",
         "0.85306853",
         "0.4217533",
         "0.09164047",
         "0.44089258",
         "0.085721076"
        ],
        [
         "17",
         "0.9308937",
         "0.66370344",
         "0.13219714",
         "0.90775305",
         "0.31721652"
        ],
        [
         "18",
         "0.31992495",
         "0.076774776",
         "0.027114093",
         "0.16169608",
         "0.6373086"
        ],
        [
         "19",
         "0.67782825",
         "0.80652267",
         "0.7144324",
         "0.2524581",
         "0.32320386"
        ],
        [
         "20",
         "0.5284482",
         "0.67163956",
         "0.074168086",
         "0.22761947",
         "0.9556624"
        ],
        [
         "21",
         "0.94764215",
         "0.107973814",
         "0.16943067",
         "0.44557625",
         "0.5458023"
        ],
        [
         "22",
         "0.20606858",
         "0.87759537",
         "0.43318695",
         "0.09370184",
         "0.24256861"
        ],
        [
         "23",
         "0.030303001",
         "0.45202553",
         "0.037123382",
         "0.043860793",
         "0.66387284"
        ],
        [
         "24",
         "0.38292444",
         "0.47545254",
         "0.4466048",
         "0.9923266",
         "0.7290829"
        ],
        [
         "25",
         "0.77128047",
         "0.12718183",
         "0.935157",
         "0.8695981",
         "0.86455953"
        ],
        [
         "26",
         "0.80975705",
         "0.37854725",
         "0.8703719",
         "0.86006844",
         "0.75754845"
        ],
        [
         "27",
         "0.6925301",
         "0.561416",
         "0.19019204",
         "0.52303743",
         "0.27677685"
        ],
        [
         "28",
         "0.823193",
         "0.96257967",
         "0.16063243",
         "0.5558295",
         "0.045555174"
        ],
        [
         "29",
         "0.25228882",
         "0.7349267",
         "0.6451157",
         "0.6065561",
         "0.4793678"
        ],
        [
         "30",
         "0.7947443",
         "0.0016815066",
         "0.58604735",
         "0.89280945",
         "0.70554596"
        ],
        [
         "31",
         "0.78843766",
         "0.7013434",
         "0.2649563",
         "0.7467464",
         "0.28009188"
        ],
        [
         "32",
         "0.44584066",
         "0.63138247",
         "0.67070824",
         "0.5600218",
         "0.76429486"
        ],
        [
         "33",
         "0.09746814",
         "0.46181637",
         "0.49393827",
         "0.8076402",
         "0.5897767"
        ],
        [
         "34",
         "0.87123054",
         "0.48417646",
         "0.2630781",
         "0.6892156",
         "0.2695443"
        ],
        [
         "35",
         "0.34481734",
         "0.15155411",
         "0.7541163",
         "0.37529844",
         "0.5428197"
        ],
        [
         "36",
         "0.6260829",
         "0.94882977",
         "0.49883288",
         "0.6017796",
         "0.08436924"
        ],
        [
         "37",
         "0.776457",
         "0.4200927",
         "0.929579",
         "0.029593527",
         "0.5726779"
        ],
        [
         "38",
         "0.042161405",
         "0.959098",
         "0.81288797",
         "0.8146829",
         "0.80667096"
        ],
        [
         "39",
         "0.24625707",
         "0.2270782",
         "0.22233284",
         "0.19044071",
         "0.48495555"
        ],
        [
         "40",
         "0.11010325",
         "0.8103752",
         "0.18672031",
         "0.5957845",
         "0.74460036"
        ],
        [
         "41",
         "0.4018643",
         "0.81808704",
         "0.9135354",
         "0.79082453",
         "0.09582901"
        ],
        [
         "42",
         "0.07384652",
         "0.8374027",
         "0.7401932",
         "0.73607427",
         "0.15316832"
        ],
        [
         "43",
         "0.580193",
         "0.9011484",
         "0.036054492",
         "0.942073",
         "0.108905554"
        ],
        [
         "44",
         "0.034367204",
         "0.56426436",
         "0.5810839",
         "0.54569405",
         "0.1050393"
        ],
        [
         "45",
         "0.6341202",
         "0.7155597",
         "0.23012424",
         "0.34894234",
         "0.5232362"
        ],
        [
         "46",
         "0.57742995",
         "0.53228754",
         "0.70700574",
         "0.8951921",
         "0.16121441"
        ],
        [
         "47",
         "0.22526187",
         "0.2908045",
         "0.18989784",
         "0.88427114",
         "0.57226276"
        ],
        [
         "48",
         "0.6884977",
         "0.6078912",
         "0.23891228",
         "0.6961492",
         "0.87754536"
        ],
        [
         "49",
         "0.46361768",
         "0.89084625",
         "0.07188547",
         "0.018096745",
         "0.42152274"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 8462
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.733178</td>\n",
       "      <td>0.695553</td>\n",
       "      <td>0.633435</td>\n",
       "      <td>0.500656</td>\n",
       "      <td>0.737202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.387885</td>\n",
       "      <td>0.263694</td>\n",
       "      <td>0.821976</td>\n",
       "      <td>0.771281</td>\n",
       "      <td>0.686281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106234</td>\n",
       "      <td>0.418982</td>\n",
       "      <td>0.834129</td>\n",
       "      <td>0.099004</td>\n",
       "      <td>0.031417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427075</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.964152</td>\n",
       "      <td>0.032465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.346969</td>\n",
       "      <td>0.835123</td>\n",
       "      <td>0.084330</td>\n",
       "      <td>0.950386</td>\n",
       "      <td>0.669154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8457</th>\n",
       "      <td>0.874422</td>\n",
       "      <td>0.742087</td>\n",
       "      <td>0.072422</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>0.546723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>0.815274</td>\n",
       "      <td>0.294159</td>\n",
       "      <td>0.923171</td>\n",
       "      <td>0.234382</td>\n",
       "      <td>0.408409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8459</th>\n",
       "      <td>0.052138</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>0.565389</td>\n",
       "      <td>0.831830</td>\n",
       "      <td>0.760738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>0.382591</td>\n",
       "      <td>0.883459</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.469120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8461</th>\n",
       "      <td>0.955669</td>\n",
       "      <td>0.458628</td>\n",
       "      <td>0.553791</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.431754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8462 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_0     col_1     col_2     col_3     col_4\n",
       "0     0.733178  0.695553  0.633435  0.500656  0.737202\n",
       "1     0.387885  0.263694  0.821976  0.771281  0.686281\n",
       "2     0.106234  0.418982  0.834129  0.099004  0.031417\n",
       "3     0.427075  0.995037  0.046403  0.964152  0.032465\n",
       "4     0.346969  0.835123  0.084330  0.950386  0.669154\n",
       "...        ...       ...       ...       ...       ...\n",
       "8457  0.874422  0.742087  0.072422  0.534825  0.546723\n",
       "8458  0.815274  0.294159  0.923171  0.234382  0.408409\n",
       "8459  0.052138  0.637868  0.565389  0.831830  0.760738\n",
       "8460  0.382591  0.883459  0.125626  0.014019  0.469120\n",
       "8461  0.955669  0.458628  0.553791  0.716113  0.431754\n",
       "\n",
       "[8462 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn=noraml_df.copy(deep=True)\n",
    "yn=dfn['attack']\n",
    "dfn.drop(columns=['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8521,    0],\n",
       "       [   0, 1479]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "yp=dt.predict(X=df)\n",
    "confusion_matrix(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples,features,func,normal=False):\n",
    "        self.samples=samples\n",
    "        self.features=features\n",
    "        self.x =torch.rand([samples,features])\n",
    "        self.y=torch.where( func(self.x) ,1,0)\n",
    "        if normal:            \n",
    "            self.x=self.x[~ self.y.bool()]\n",
    "            self.samples=self.x.shape[0]\n",
    "            self.y=torch.zeros(self.samples)\n",
    "        self.y=self.y.float()\n",
    "        print(self.y.mean(-1))\n",
    "        print(samples,self.y.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx].unsqueeze(-1).cuda(),self.y[idx].unsqueeze(-1).cuda(),self.y[idx].unsqueeze(-1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='./tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.adj=dense_to_sparse(torch.ones(2708,2708))[0].cuda()\n",
    "        self.w=torch.nn.Parameter(torch.rand(2708*2708,requires_grad=True))\n",
    "        self.w.requires_grad=True\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, _ = data.x, data.edge_index\n",
    "        if x.dim()==3:\n",
    "            batch=x.shape[0]\n",
    "            edge_index=self.adj.repeat(batch)\n",
    "            edge_w=self.w.repeat(batch)\n",
    "        else:\n",
    "            edge_index=self.adj\n",
    "            edge_w=self.w      \n",
    "        x = self.conv1(x, edge_index=edge_index,edge_weight=edge_w)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index=edge_index,edge_weight=edge_w)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3666371., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "model.w.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1151770.7500, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1300\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 0., 1., 2., 0., 1., 2.], grad_fn=<RepeatBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(3).float().requires_grad_(True).repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(torch.nn.Module):\n",
    "    def __init__(self,features):\n",
    "        super(HiddenLayer, self).__init__()    \n",
    "        self.first = torch.nn.Linear(features, features)  # Input size is 2 (1st and last features), 64 hidden units\n",
    "        self.relu = torch.nn.ReLU()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self,features,embeding,hidden,hidden_layers):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        # Define a neural network with a few layers to learn nonlinear relationships\n",
    "        self.enc=torch.nn.Sequential(\n",
    "            torch.nn.Linear(features, embeding),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(embeding, hidden),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                HiddenLayer(hidden)\n",
    "                for i in range(hidden_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.dec=torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden, embeding),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.last = torch.nn.Linear(embeding, 1)  # Output layer, 1 unit (binary classification)\n",
    "        self.sigmoid = torch.nn.Sigmoid()  # Sigmoid for binary classification output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.dec(x)\n",
    "        x = self.last(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from src.models.BaseModel import BaseModel\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,features,embeding,hidden,hidden_layers):\n",
    "        super().__init__()\n",
    "        self.node_num=features\n",
    "        self.conv1 = GCNConv(1, embeding)\n",
    "        self.conv2 = GCNConv(embeding, hidden)\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                GCNConv(hidden, hidden)\n",
    "                for i in range(hidden_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.conv3 = GCNConv(hidden, 1)\n",
    "        self.last = torch.nn.Linear(features, 1)  # Output layer, 1 unit (binary classification)\n",
    "        self.sigmoid = torch.nn.Sigmoid()  # Sigmoid for binary classification output\n",
    "        self.edge_index=torch.tensor([[0,features-1],[features-1,0]]).cuda()\n",
    "\n",
    "    def forward(self, data:torch.Tensor):\n",
    "        x = self.conv1(data, self.edge_index)\n",
    "        x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, self.edge_index)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self.edge_index)\n",
    "            x = F.relu(x)\n",
    "            # x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, self.edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.last(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "        \n",
    "class GCN_AT(BaseModel):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.node_embeddings=torch.nn.Parameter(\n",
    "            torch.rand(\n",
    "                self.node_num,\n",
    "                self.param.embedding_dimension                )\n",
    "            )\n",
    "        \n",
    "        self.conv_first = GCNConv(1, self.param.out_layer_inter_dim)\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                GCNConv(self.param.out_layer_inter_dim, self.param.out_layer_inter_dim)\n",
    "                for i in range(self.param.out_layer_num)\n",
    "            ]\n",
    "        )\n",
    "        self.conv_last = GCNConv(self.param.out_layer_inter_dim,1)\n",
    "        self.init_parameters()\n",
    "        \n",
    "    def getAdj(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            adj_matrix (Tensor): Sparse adjacency matrix (N, N)\n",
    "        \"\"\"\n",
    "        # Normalize embeddings for stable cosine similarity\n",
    "        normalized_embeddings = F.normalize(self.node_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Compute cosine similarity matrix\n",
    "        sim_matrix = torch.mm(normalized_embeddings, normalized_embeddings.t())\n",
    "        \n",
    "        # Ensure self-similarity is not selected\n",
    "        sim_matrix.fill_diagonal_(-1)  # Set diagonal to -1 to exclude self-connections\n",
    "        \n",
    "        # # Get top-k neighbors for each node\n",
    "        topk_values, topk_indices = torch.topk(sim_matrix, k=self.param.topk, dim=1)\n",
    "        \n",
    "        # # Create binary adjacency mask\n",
    "        adj_mask = torch.zeros_like(sim_matrix)\n",
    "        adj_mask.scatter_(1, topk_indices, 1.0)\n",
    "        \n",
    "        # For undirected graphs, ensure symmetric connections\n",
    "        # if not self.directed:\n",
    "        # adj_mask = torch.max(sim_matrix, sim_matrix.t())\n",
    "        # adj_mask.fill_diagonal_(1)  # Add self-loops\n",
    "        \n",
    "        return adj_mask \n",
    "    \n",
    "    def init_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_embeddings)   \n",
    "    \n",
    "    def pre_forward(self, data:torch.Tensor):\n",
    "        adj,_=dense_to_sparse(self.getAdj())\n",
    "        x = self.conv_first(data, adj)\n",
    "        x = F.relu(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, adj)\n",
    "            x = F.relu(x)\n",
    "            # x = F.dropout(x, training=self.training)\n",
    "        x = self.conv_last(x, adj)\n",
    "        x = F.relu(x)\n",
    "        # x = self.last(x.squeeze(-1))\n",
    "        # x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.cuda()\n",
    "    metric=BinaryConfusionMatrix()\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        t=tqdm.tqdm(test_loader,leave=False)\n",
    "        for features, labels in t:\n",
    "            # Forward pass\n",
    "            outputs = model(features.detach().cuda())\n",
    "            \n",
    "            # Assuming binary classification: outputs are probabilities\n",
    "            # predicted = torch.where((outputs > 0.5),1,0).float()  # Convert probabilities to binary predictions\n",
    "            metric.update(outputs.squeeze(),labels.squeeze())\n",
    "            # Calculate accuracy\n",
    "            # total += labels.size(0)\n",
    "            # correct += (predicted.cpu() == labels).sum().item()\n",
    "    r=metric.compute().tolist()\n",
    "    # accuracy = 100 * correct / total\n",
    "    return r[0][0]/(r[0][0]+r[0][1]),r[1][1]/(r[1][0]+r[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop\n",
    "def train_model(model:torch.nn.Module, \n",
    "                train_data_loader:torch.utils.data.DataLoader, \n",
    "                test_data_loader:torch.utils.data.DataLoader,\n",
    "                epochs:int):\n",
    "    criterion = torch.nn.MSELoss() # Binary Cross-Entropy Loss for classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model=model.train().cuda()\n",
    "    t=tqdm.tqdm(torch.arange(epochs))\n",
    "    t.set_postfix_str(\"{Loss:.4f}\")\n",
    "    train_p_recall=[]\n",
    "    train_n_recall=[]\n",
    "    test_p_recall=[]\n",
    "    test_n_recall=[]   \n",
    "    _loss=[]\n",
    "    for epoch in t:\n",
    "        for features, labels in train_data_loader:\n",
    "            # Extract the 1st and last features only\n",
    "            # x = features[:, [0, -1]]  # Select 1st and last feature\n",
    "            # labels = labels.view(-1, 1)  # Reshape labels for BCELoss\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(features.cuda())\n",
    "            loss = criterion(outputs, labels.cuda().float())\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        t.set_postfix({\"Loss\": loss.item()})\n",
    "        _loss.append(loss.item())\n",
    "        rtrain=test_model(model,train_data_loader)\n",
    "        rtest=test_model(model,test_data_loader)\n",
    "        train_p_recall.append(rtrain[0])\n",
    "        train_n_recall.append(rtrain[1])\n",
    "        test_p_recall.append(rtest[0])\n",
    "        test_n_recall.append(rtest[1])\n",
    "        \n",
    "    return pd.DataFrame({\"train_p_recall\":train_p_recall,\n",
    "                         \"train_n_recall\":train_n_recall,\n",
    "                         \"test_p_recall\":train_p_recall,\n",
    "                         \"test_n_recall\":test_n_recall,\n",
    "                         \"loss\":_loss})\n",
    "        \n",
    "\n",
    "# Note: You need to provide a data loader (`data_loader`) that yields batches of your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_loop import train\n",
    "from util.params import Params\n",
    "from util.consts import Tasks\n",
    "from util.env import set_param\n",
    "from datasets.TimeDataset import TimeDataset\n",
    "from datasets.CurrentDataset import CurrentDataset\n",
    "sensors=noraml_df.columns.drop(\"attack\")\n",
    "\n",
    "param=Params()\n",
    "param.epoch=5\n",
    "param.task=Tasks.current_label\n",
    "param.batch=16\n",
    "param.topk=2\n",
    "set_param(param)\n",
    "\n",
    "\n",
    "normal_dataset=CurrentDataset(noraml_df,sensors,[])\n",
    "abnormal_dataset=CurrentDataset(abnoraml_df,sensors,[],mode=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0693],\n",
       "         [0.3560],\n",
       "         [0.4138],\n",
       "         [0.1085],\n",
       "         [0.7405]], device='cuda:0'),\n",
       " tensor([], device='cuda:0', size=(0, 1)),\n",
       " tensor([0.], device='cuda:0'))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch_geometric.data\n",
    "import torch_geometric.nn\n",
    "\n",
    "class GAT_PG(torch.nn.Module):\n",
    "    \"\"\"docstring for GAT_PG.\"\"\"\n",
    "    def __init__(self, **kwarg):\n",
    "        super(GAT_PG, self).__init__(**kwarg)\n",
    "        self.gat=torch_geometric.nn.GCNConv(1,1)\n",
    "        self.lin=torch.nn.Linear(features,1)\n",
    "        self.adj=torch.nn.Parameter(dense_to_sparse(torch.ones(features,features))[0],requires_grad=False)\n",
    "        self.w=torch.nn.Parameter(torch.rand(features*features),requires_grad=True)\n",
    "        \n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "        x=x.detach().clone()\n",
    "        if x.dim()==3: #batched\n",
    "            batch=x.shape[0]\n",
    "            xl=[torch_geometric.data.Data(x=x_,edge_index=self.adj,edge_attr=self.w) for x_ in x]\n",
    "            batched=torch_geometric.data.Batch.from_data_list(xl)\n",
    "            x=self.gat(batched.x,edge_index=batched.edge_index,edge_weight=batched.edge_weight)\n",
    "            x=x.view(batch,-1)\n",
    "        else:\n",
    "            x=self.gat(x,edge_index=self.adj,edge_weight=self.w)\n",
    "            x=x.squeeze(-1)\n",
    "        x=self.lin(x)\n",
    "        x=F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_PGDS(torch.nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(GAT_PGDS, self).__init__()\n",
    "        self.gat = torch_geometric.nn.GCNConv(1, 1)\n",
    "        self.lin = torch.nn.Linear(features, 1)\n",
    "        adj_matrix = torch.ones(features, features).cuda()\n",
    "        self.adj = dense_to_sparse(adj_matrix)[0]  # edge_index shape [2, num_edges]\n",
    "        self.num_edges = self.adj.size(1)\n",
    "        self.w = torch.nn.Parameter(torch.rand(self.num_edges), requires_grad=True)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if x.dim() == 3:  # Batched input [batch_size, num_nodes, 1]\n",
    "            batch_size, num_nodes, _ = x.shape\n",
    "            x = x.view(-1, 1)  # Flatten to [batch_size * num_nodes, 1]\n",
    "            \n",
    "            # Adjust edge_index for each graph in the batch\n",
    "            offsets = torch.arange(batch_size, device=x.device) * num_nodes\n",
    "            edge_index = (self.adj.unsqueeze(1) + offsets.view(-1, 1, 1)).view(2, -1)\n",
    "            \n",
    "            # Repeat self.w for each graph in the batch\n",
    "            edge_weight = self.w.repeat(batch_size)\n",
    "            \n",
    "            x = self.gat(x, edge_index, edge_weight)\n",
    "            x = x.view(batch_size, -1)\n",
    "        else:\n",
    "            x = self.gat(x, self.adj, self.w)\n",
    "            x = x.squeeze(-1)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_loader=torch.utils.data.DataLoader(normal_dataset,param.batch,shuffle=True)\n",
    "abnormal_loader=torch.utils.data.DataLoader(abnormal_dataset,param.batch)\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "# model = SimpleModel(features,64,32,0)\n",
    "model=GAT_PG()#GCN_AT(node_num=features)\n",
    "model=model.cuda()\n",
    "model=model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5235], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(normal_dataset.__getitem__(0)[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=model(normal_dataset.__getitem__(0)[0].cuda())-.53\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moji\\AppData\\Local\\Temp\\ipykernel_16344\\3815194156.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  l.grad\n"
     ]
    }
   ],
   "source": [
    "l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2446, device='cuda:0')\n",
      "torch.Size([40])\n",
      "Parameter containing:\n",
      "tensor([0.4915, 0.3565, 0.0060, 0.1899, 0.5869, 0.6925, 0.7799, 0.5875, 0.0289,\n",
      "        0.9239, 0.7400, 0.7563, 0.4715, 0.0762, 0.4811, 0.0664, 0.2827, 0.3466,\n",
      "        0.9487, 0.4724, 0.1966, 0.5589, 0.5069, 0.3215, 0.3752],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model.w.sum())\n",
    "    \n",
    "    a,w=dense_to_sparse(model.adj)\n",
    "    print(a[0].shape)\n",
    "    print(model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj torch.Size([2, 25]) False\n",
      "w torch.Size([25]) True\n",
      "gat.bias torch.Size([1]) True\n",
      "gat.lin.weight torch.Size([1, 1]) True\n",
      "lin.weight torch.Size([1, 5]) True\n",
      "lin.bias torch.Size([1]) True\n"
     ]
    }
   ],
   "source": [
    "for name,p in model.named_parameters():\n",
    "    print(name,p.shape , p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 534/534 [00:06<00:00, 83.18it/s, loss=0.0362]\n",
      "100%|██████████| 534/534 [00:06<00:00, 83.87it/s, loss=0.00683]\n",
      "100%|██████████| 534/534 [00:06<00:00, 82.37it/s, loss=0.00402]\n",
      "100%|██████████| 534/534 [00:06<00:00, 82.92it/s, loss=0.000962]\n",
      "100%|██████████| 534/534 [00:06<00:00, 82.88it/s, loss=0.000775]\n",
      "100%|██████████| 534/534 [00:06<00:00, 82.69it/s, loss=0.00033] \n",
      "100%|██████████| 534/534 [00:06<00:00, 81.84it/s, loss=0.000238]\n",
      "100%|██████████| 534/534 [00:06<00:00, 85.12it/s, loss=5.9e-5]  \n",
      "100%|██████████| 534/534 [00:06<00:00, 82.83it/s, loss=9.93e-5] \n",
      "100%|██████████| 534/534 [00:06<00:00, 82.86it/s, loss=0.000257]\n",
      " 12%|█▏        | 63/534 [00:00<00:05, 80.59it/s, loss=8.37e-5] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m acu_loss=\u001b[32m0\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b,(data) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(t):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     y=\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     loss=loss_func(y,data[\u001b[32m2\u001b[39m])\n\u001b[32m     26\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mGAT_PG.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     18\u001b[39m batch=x.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     19\u001b[39m xl=[torch_geometric.data.Data(x=x_,edge_index=\u001b[38;5;28mself\u001b[39m.adj,edge_attr=\u001b[38;5;28mself\u001b[39m.w) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m batched=\u001b[43mtorch_geometric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m x=\u001b[38;5;28mself\u001b[39m.gat(batched.x,edge_index=batched.edge_index,edge_weight=batched.edge_weight)\n\u001b[32m     22\u001b[39m x=x.view(batch,-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[39m, in \u001b[36mBatch.from_data_list\u001b[39m\u001b[34m(cls, data_list, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_data_list\u001b[39m(\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     88\u001b[39m ) -> Self:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     batch, slice_dict, inc_dict = \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     batch._num_graphs = \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    107\u001b[39m     batch._slice_dict = slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\data\\collate.py:109\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m value, slices, incs = \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value.is_cuda:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\data\\collate.py:169\u001b[39m, in \u001b[36m_collate\u001b[39m\u001b[34m(key, values, data_list, stores, increment)\u001b[39m\n\u001b[32m    167\u001b[39m slices = cumsum(sizes)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     incs = \u001b[43mget_incs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m incs.dim() > \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[-\u001b[32m1\u001b[39m]) != \u001b[32m0\u001b[39m:\n\u001b[32m    171\u001b[39m         values = [\n\u001b[32m    172\u001b[39m             value + inc.to(value.device)\n\u001b[32m    173\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[32m    174\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\data\\collate.py:335\u001b[39m, in \u001b[36mget_incs\u001b[39m\u001b[34m(key, values, data_list, stores)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    334\u001b[39m     repeats = torch.tensor(repeats)\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\utils\\functions.py:24\u001b[39m, in \u001b[36mcumsum\u001b[39m\u001b[34m(x, dim)\u001b[39m\n\u001b[32m     21\u001b[39m out = x.new_empty(size)\n\u001b[32m     23\u001b[39m out.narrow(dim, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).zero_()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=param.learning_rate, weight_decay=param.decay\n",
    ")\n",
    "\n",
    "acu_loss = 0\n",
    "min_loss = 1e8\n",
    "min_train_loss = 1e8\n",
    "\n",
    "epoch = param.epoch\n",
    "early_stop_win = 15\n",
    "model.to(param.device)\n",
    "\n",
    "stop_improve_count = 0\n",
    "\n",
    "acu_loss = 0\n",
    "loss_func = torch.nn.L1Loss()  # param.loss_function()\n",
    "\n",
    "for epoch in range(param.epoch):\n",
    "    t=tqdm.tqdm(normal_loader,postfix=\"{loss}\",)\n",
    "    acu_loss=0\n",
    "    for b,(data) in enumerate(t):\n",
    "        y=model(data[0])\n",
    "        loss=loss_func(y,data[2])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acu_loss += loss.item()\n",
    "        t.set_postfix({\"loss\":loss.item()})\n",
    "    t.set_postfix({\"loss\":loss.item()})\n",
    "    t.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.1259, device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([0.7120, 0.4131, 0.6247, 0.2921, 0.5111, 0.1222, 0.6396, 0.4460, 0.4027,\n",
      "        0.7959, 0.2787, 0.8526, 0.6257, 0.7505, 0.6336, 0.8621, 0.7057, 0.4243,\n",
      "        0.2755, 0.4535, 0.0611, 0.6223, 0.3871, 0.7866, 0.4474],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model.w.sum())\n",
    "    print(model.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoc 1 / 5:   0%|          | 0/536 [00:00<?, ?it/s, {loss} {val_loss}]"
     ]
    }
   ],
   "source": [
    "train(model=model,train_dataloader=normal_loader,val_dataloader=abnormal_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result=train_model(model=model,\n",
    "                   train_data_loader=normal_loader,\n",
    "                   test_data_loader=abnormal_loader,\n",
    "                   epochs=50)\n",
    "result.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp.squeeze().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "yp=model(noram_dataset.x.cuda())\n",
    "c=BinaryConfusionMatrix()\n",
    "c.update(noram_dataset.y.detach(),yp.detach().squeeze())\n",
    "c.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[150:,\"loss\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot(y=[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.iloc[:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "dataset = Planetoid('/tmp/Planetoid', 'Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.edge_weight = torch.nn.Parameter(torch.ones(data.num_edges))\n",
    "        self.conv1 = GCNConv(1, 16)\n",
    "        self.conv2 = GCNConv(16,1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv1(x, edge_index, self.edge_weight.sigmoid()).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, self.edge_weight.sigmoid())\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    F.nll_loss(out[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(data.x, data.edge_index), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    print(model.edge_weight[:5])\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_acc, best_val_acc, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_12_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
