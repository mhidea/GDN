{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from models import GDN\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[ 0,  1,  2,  3,  4],\n",
                        "        [ 5,  6,  7,  8,  9],\n",
                        "        [10, 11, 12, 13, 14],\n",
                        "        [15, 16, 17, 18, 19],\n",
                        "        [20, 21, 22, 23, 24]])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0,  1,  2],\n",
                            "        [ 5,  6,  7],\n",
                            "        [10, 11, 12],\n",
                            "        [15, 16, 17],\n",
                            "        [20, 21, 22]])"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "l=torch.arange(25).reshape(5,-1)\n",
                "print(l)\n",
                "l[:,0:3]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Number of unique items and the size of each embedding vector\n",
                "num_items = 10  # Assume we have 10 unique items\n",
                "embedding_dim = 4  # Each item will be represented as a 4-dimensional vector\n",
                "\n",
                "# Define the embedding layer\n",
                "w=torch.randn([num_items, embedding_dim])\n",
                "w\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Model(torch.nn.Module):\n",
                "    def __init__(self):\n",
                "        super(Model,self).__init__()\n",
                "        self.l=torch.nn.Linear(5,6)\n",
                "        self.w=torch.nn.Parameter(\n",
                "            torch.ones([3,6])\n",
                "        )\n",
                "    def forward(self,x):\n",
                "        x=self.l(x)\n",
                "        x=self.w.matmul(x)\n",
                "        return x\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([3, 6])\n",
                        "torch.Size([6, 5])\n",
                        "torch.Size([6])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([-0.1346, -0.1346, -0.1346], grad_fn=<MvBackward0>)"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model=Model()\n",
                "for p in model.parameters():\n",
                "    print(p.shape)\n",
                "model(torch.rand(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.4949,  0.2817, -0.0755,  0.4635],\n",
                            "        [-0.2632,  0.1586, -0.3282, -0.2517],\n",
                            "        [-0.0466,  0.0246,  0.1128,  0.2269],\n",
                            "        [ 0.4029,  0.1313, -0.0139,  0.0515],\n",
                            "        [-0.3996, -0.3556, -0.1169,  0.2630],\n",
                            "        [-0.2006,  0.3181,  0.1958, -0.2306],\n",
                            "        [-0.2965,  0.0233, -0.3822,  0.1961],\n",
                            "        [-0.1119,  0.3873, -0.1108, -0.0181],\n",
                            "        [-0.3743, -0.3277, -0.4429,  0.4875],\n",
                            "        [ 0.1949,  0.3815, -0.3666,  0.3399]])"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nn.init.kaiming_uniform_(w, a=torch.math.sqrt(5))\n",
                "w"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "embedding_layer = nn.Embedding(num_items, embedding_dim,_weight=w)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([0.3774, 0.9605, 0.5294, 0.7933, 0.0470, 0.5367, 0.1014, 0.7028])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([0.7547, 1.9210, 1.0588, 1.5865, 0.0000, 1.0734, 0.0000, 1.4056])"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a=torch.rand(8)\n",
                "print(a)\n",
                "dp = nn.Dropout(0.5)\n",
                "dp(a)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([-0.0745,  0.6489,  0.0623, -0.5137])"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "w[5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Item IDs: tensor([2, 5, 7])\n",
                        "Corresponding Embeddings:\n",
                        " tensor([[ 0.9213, -2.3571, -0.0884,  0.1023],\n",
                        "        [-0.0745,  0.6489,  0.0623, -0.5137],\n",
                        "        [ 1.1842,  0.6372,  1.7921, -0.7124]], grad_fn=<EmbeddingBackward0>)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Example item IDs (e.g., items bought by a user)\n",
                "item_ids = torch.tensor([2, 5, 7], dtype=torch.long)\n",
                "\n",
                "# Get the embeddings for the given item IDs\n",
                "item_embeddings = embedding_layer(item_ids)\n",
                "\n",
                "print(\"Item IDs:\", item_ids)\n",
                "print(\"Corresponding Embeddings:\\n\", item_embeddings)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.4507, -1.4142, -0.7936,  1.3749],\n",
                            "        [-1.3862,  0.7112, -0.6170, -0.4011],\n",
                            "        [ 0.9355,  0.7030,  1.4105, -0.9739]],\n",
                            "       grad_fn=<NativeBatchNormBackward0>)"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bn=nn.BatchNorm1d(embedding_dim)\n",
                "out:torch.Tensor=bn(item_embeddings)\n",
                "out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.6865,  0.4370,  0.7290, -0.1278],\n",
                            "        [ 0.7275, -1.3833, -1.4140,  1.2836],\n",
                            "        [-1.4140,  0.9463,  0.6850, -1.1558]],\n",
                            "       grad_fn=<NativeBatchNormBackward0>)"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bn(torch.randn(3, embedding_dim))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cuda_12_4",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}