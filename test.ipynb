{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from models.mine.MSTGAT import MSTGAT\n",
                "from models.GDN import GDN\n",
                "from util.params import Params\n",
                "from util.env import set_param\n",
                "import torch\n",
                "from torch_geometric.utils import dense_to_sparse\n",
                "import tqdm\n",
                "from datasets.TimeDataset import TimeDataset\n",
                "from util.consts import Tasks,Datasets\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "from util.preprocess import findSensorActuator\n",
                "\n",
                "param=Params()\n",
                "param.learning_rate=.001\n",
                "param.batch=32\n",
                "param.epoch=60\n",
                "param.embedding_dimension=128\n",
                "param.topk=15\n",
                "kernel_size=16\n",
                "gamma1=.5\n",
                "gamma2=.8\n",
                "param.task=Tasks.next_sensors\n",
                "param.dataset=Datasets.dummy\n",
                "set_param(param)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "model=GDN(node_num=30)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "cp=model.embedding.weight.detach().clone()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "x=torch.rand((20,30,param.window_length),requires_grad=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "opt=torch.optim.Adam(lr=.1,params=model.parameters())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "opt.zero_grad()\n",
                "loss=model(x).mean()-1\n",
                "loss.backward()\n",
                "opt.step()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor(383.9877, grad_fn=<SumBackward0>)"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "(cp-model.embedding.weight).abs().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch_geometric.nn.models import GAT\n",
                "\n",
                "gat=GAT(in_channels=10,hidden_channels=30,num_layers=1,out_channels=10,v2=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch_geometric.utils import dense_to_sparse\n",
                "\n",
                "index,w=dense_to_sparse(torch.randint(low=0,high=2,size=(20,20)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "node_num=20\n",
                "batch_num=40\n",
                "embedding=torch.nn.Embedding(node_num,60)\n",
                "embedding.weight"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_embeddings = embedding(torch.arange(node_num))\n",
                "\n",
                "weights_arr = all_embeddings.detach().clone()\n",
                "all_embeddings = all_embeddings.repeat(batch_num, 1)\n",
                "\n",
                "weights = weights_arr.view(node_num, -1)\n",
                "\n",
                "cos_ji_mat = torch.matmul(weights, weights.T)\n",
                "normed_mat = torch.matmul(\n",
                "    weights.norm(dim=-1).view(-1, 1), weights.norm(dim=-1).view(1, -1)\n",
                ")\n",
                "cos_ji_mat = cos_ji_mat / normed_mat\n",
                "\n",
                "dim = weights.shape[-1]\n",
                "topk_num = 15\n",
                "\n",
                "topk_indices_ji = torch.topk(cos_ji_mat, topk_num, dim=-1)[1]\n",
                "\n",
                "learned_graph = topk_indices_ji"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([20, 15])"
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "learned_graph.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AssertionError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m x=torch.rand(\u001b[32m40\u001b[39m,\u001b[32m20\u001b[39m,\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mgat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\nn\\models\\basic_gnn.py:254\u001b[39m, in \u001b[36mBasicGNN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight, edge_attr, batch, batch_size, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001b[39m\n\u001b[32m    252\u001b[39m     x = conv(x, edge_index, edge_weight=edge_weight)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_edge_attr:\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     x = \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    256\u001b[39m     x = conv(x, edge_index)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:281\u001b[39m, in \u001b[36mGATv2Conv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[39m\n\u001b[32m    279\u001b[39m x_r: OptTensor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m x.dim() == \u001b[32m2\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    284\u001b[39m         res = \u001b[38;5;28mself\u001b[39m.res(x)\n",
                        "\u001b[31mAssertionError\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "x=torch.rand(40,20,10)\n",
                "gat(x=x,edge_index=index,edge_weight=w)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preapareDF_modal( dataset):\n",
                "    _train_original = pd.read_csv(\n",
                "        f\"./data/{dataset}/train.csv\",\n",
                "        sep=\",\",\n",
                "        index_col=0,\n",
                "    )\n",
                "    _test_original = pd.read_csv(\n",
                "        f\"./data/{dataset}/test.csv\",\n",
                "        sep=\",\",\n",
                "        index_col=0,\n",
                "    )\n",
                "\n",
                "    #     columns = [\n",
                "    #     col for col in _train_original if col.strip() not in [\"datetime\", \"Timestamp\"]\n",
                "    # ]\n",
                "    # _train_original=_train_original[columns]\n",
                "    # _test_original=_test_original[columns]\n",
                "\n",
                "    for i, col in enumerate(_train_original.columns):\n",
                "        assert _train_original.columns[i] == _test_original.columns[i]\n",
                "    stripped_columns = [col.split(\"_\")[0] for col in _train_original.columns]\n",
                "    adj = torch.zeros(len(stripped_columns), len(stripped_columns))\n",
                "    for i in range(len(stripped_columns)):\n",
                "        for j in range(len(stripped_columns)):\n",
                "            if stripped_columns[i] == stripped_columns[j]:\n",
                "                adj[i][j] = 1\n",
                "    return _train_original, _test_original, adj"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepareDF( scale, dataset):\n",
                "    _train_original = pd.read_csv(\n",
                "        f\"./data/{dataset}/train.csv\", sep=\",\", index_col=0\n",
                "    )\n",
                "    _test_original = pd.read_csv(\n",
                "        f\"./data/{dataset}/test.csv\", sep=\",\", index_col=0\n",
                "    )\n",
                "    _columns = findSensorActuator(_train_original)\n",
                "    sensors, actuators, consts = _columns\n",
                "    print(\"#####################################\")\n",
                "    print(\"sensors count: \", len(sensors))\n",
                "    print(\"actuators count: \", len(actuators))\n",
                "    print(\"consts count: \", len(consts))\n",
                "    print(\"consts: \", consts)\n",
                "    print(\"#####################################\")\n",
                "    print(sensors)\n",
                "    if scale:\n",
                "        scaler = MinMaxScaler()\n",
                "        # Initialize the MinMaxScaler\n",
                "        \n",
                "\n",
                "        # Fit the scaler on the first dataset\n",
                "        scaler.fit(_train_original[sensors])\n",
                "\n",
                "        # Transform both datasets using the same scaler\n",
                "        _train_original[sensors] = scaler.transform(_train_original[sensors])\n",
                "\n",
                "        _test_original[sensors] = scaler.transform(_test_original[sensors])\n",
                "    # if \"attack\" in _train_original.columns:\n",
                "    #     _train_original = _train_original.drop(columns=[\"attack\"])\n",
                "    return _train_original, _test_original, _columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test, adj=preapareDF_modal(param.dataset.value)\n",
                "sensors=train.columns\n",
                "actuators=[]\n",
                "train_dataset=TimeDataset(                train,\n",
                "                sensor_list=sensors,\n",
                "                actuator_list=actuators,\n",
                "                mode=\"train\",)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create dataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=param.batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "node_num=len(sensors)\n",
                "m=MSTGAT(node_num=node_num,adj=adj.cuda(),gamma1=gamma1,gamma2=gamma2,kernel_size=kernel_size)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TRAIN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "epoc 1 / 60:   0%|          | 0/274 [00:00<?, ?it/s, {loss} {val_loss}]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "epoc 1 / 60:   0%|          | 0/274 [00:02<?, ?it/s, {loss} {val_loss}]\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m i = \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[32m     13\u001b[39m acu_loss=\u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindowed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m-\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\datasets\\TimeDataset.py:46\u001b[39m, in \u001b[36mTimeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     42\u001b[39m     start = idx * \u001b[38;5;28mself\u001b[39m.stride\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf_sensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m         .requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     48\u001b[39m         .contiguous(),\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mself\u001b[39m.df_sensor[start + \u001b[38;5;28mself\u001b[39m.window_length]\n\u001b[32m     50\u001b[39m         .to(device=\u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     51\u001b[39m         .requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     52\u001b[39m         .contiguous(),\n\u001b[32m     53\u001b[39m         \u001b[38;5;28mself\u001b[39m.label[start + \u001b[38;5;28mself\u001b[39m.window_length, :]\n\u001b[32m     54\u001b[39m         \u001b[38;5;66;03m# .unsqueeze()\u001b[39;00m\n\u001b[32m     55\u001b[39m         .requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m).to(device=\u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     56\u001b[39m     )\n",
                        "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
                    ]
                }
            ],
            "source": [
                "opt= torch.optim.Adam(m.parameters(),lr=param.learning_rate)\n",
                "m=m.train().cuda()\n",
                "total_samples = train_dataloader.dataset.__len__()\n",
                "avg_loss=0\n",
                "for epoch in range(param.epoch):\n",
                "    t=tqdm.tqdm(\n",
                "            train_dataloader,\n",
                "            desc=\"epoc {} / {}\".format((epoch + 1), param.epoch),\n",
                "            postfix=\"{loss} {val_loss}\",\n",
                "            position=0,\n",
                "        )\n",
                "    i = len(train_dataloader)\n",
                "    acu_loss=0\n",
                "    for b, (windowed_x, y, next_label) in enumerate(t):\n",
                "        i-=1\n",
                "        opt.zero_grad(set_to_none=True)\n",
                "        loss=m.loss(windowed_x.cuda(), y.cuda())\n",
                "        loss.backward()\n",
                "        t.set_postfix({\"loss\": (loss.item() / windowed_x.shape[0]), \"val_loss\": avg_loss})\n",
                "        opt.step()\n",
                "        acu_loss+=loss.detach().clone().item()\n",
                "        if i == 0:\n",
                "            avg_loss = acu_loss / total_samples"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cuda_12_4",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
