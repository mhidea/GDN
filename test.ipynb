{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from models.GDN import GDN\n",
                "from util.consts import Tasks\n",
                "from models.BaseMode import BaseModel\n",
                "import torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([-1,  1,  1, -1,  1])\n"
                    ]
                }
            ],
            "source": [
                "# Example tensor\n",
                "tensor = torch.tensor([0.5, 1.2, 3.7, 0.9, 2.5])\n",
                "\n",
                "# Define threshold and value R\n",
                "threshold = 1.0\n",
                "R = -1\n",
                "\n",
                "# Apply the mapping\n",
                "new_tensor = torch.where(tensor > threshold, torch.tensor(1), torch.tensor(R))\n",
                "\n",
                "print(new_tensor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([False, False, False, False, False, False, False, False, False, False])"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x=torch.arange(1,11).float()\n",
                "y=x+1\n",
                "l=torch.nn.MSELoss(reduce=False)\n",
                "l(x,y)>1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature=4\n",
                "\n",
                "a=[]\n",
                "b=[]\n",
                "for i in range(feature):\n",
                "    for j in range(feature):\n",
                "        if i!=j:\n",
                "            a.append(i)\n",
                "            b.append(j)\n",
                "edges=[torch.tensor([a,b])]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "m = GDN(\n",
                "    edge_index_sets=edges,topk=2, node_num=feature, task=Tasks.next_label\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "mat1 and mat2 shapes cannot be multiplied (40x3 and 10x64)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      2\u001b[39m x = torch.rand([\u001b[32m10\u001b[39m, feature, \u001b[32m3\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\BaseMode.py:25\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, data, org_edge_index)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, org_edge_index):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task == Tasks.next_features:\n\u001b[32m     28\u001b[39m         out = out.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.node_num)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\GDN.py:195\u001b[39m, in \u001b[36mGDN.pre_forward\u001b[39m\u001b[34m(self, data, org_edge_index)\u001b[39m\n\u001b[32m    190\u001b[39m     gated_edge_index = torch.cat((gated_j, gated_i), dim=\u001b[32m0\u001b[39m)\n\u001b[32m    192\u001b[39m     batch_gated_edge_index = get_batch_edge_index(\n\u001b[32m    193\u001b[39m         gated_edge_index, batch_num, node_num\n\u001b[32m    194\u001b[39m     ).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     gcn_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgnn_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_gated_edge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_num\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_num\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     gcn_outs.append(gcn_out)\n\u001b[32m    204\u001b[39m x = torch.cat(gcn_outs, dim=\u001b[32m1\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\GDN.py:72\u001b[39m, in \u001b[36mGNNLayer.forward\u001b[39m\u001b[34m(self, x, edge_index, embedding, node_num)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, embedding=\u001b[38;5;28;01mNone\u001b[39;00m, node_num=\u001b[32m0\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     out, (new_edge_index, att_weight) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attention_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.att_weight_1 = att_weight\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m.edge_index_1 = new_edge_index\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\graph_layer.py:65\u001b[39m, in \u001b[36mGraphLayer.forward\u001b[39m\u001b[34m(self, x, edge_index, embedding, return_attention_weights)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.is_tensor(x):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     x = (x, x)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (40x3 and 10x64)"
                    ]
                }
            ],
            "source": [
                "\n",
                "x = torch.rand([10, feature, 3])\n",
                "m(x, None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "tuple index out of range",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m x=torch.rand([\u001b[32m10\u001b[39m,\u001b[32m4\u001b[39m,\u001b[32m3\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\moji\\miniconda3\\envs\\cuda_12_4\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\BaseMode.py:25\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, data, org_edge_index)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, org_edge_index):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task == Tasks.next_features:\n\u001b[32m     28\u001b[39m         out = out.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.node_num)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\thesis\\GDN\\src\\models\\GDN.py:148\u001b[39m, in \u001b[36mGDN.pre_forward\u001b[39m\u001b[34m(self, data, org_edge_index)\u001b[39m\n\u001b[32m    146\u001b[39m gcn_outs = []\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, edge_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(edge_index_sets):\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     edge_num = \u001b[43medge_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    149\u001b[39m     cache_edge_index = \u001b[38;5;28mself\u001b[39m.cache_edge_index_sets[i]\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    152\u001b[39m         cache_edge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    153\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m cache_edge_index.shape[\u001b[32m1\u001b[39m] != edge_num * batch_num\n\u001b[32m    154\u001b[39m     ):\n",
                        "\u001b[31mIndexError\u001b[39m: tuple index out of range"
                    ]
                }
            ],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[ 0,  1,  2,  3,  4],\n",
                        "        [ 5,  6,  7,  8,  9],\n",
                        "        [10, 11, 12, 13, 14],\n",
                        "        [15, 16, 17, 18, 19],\n",
                        "        [20, 21, 22, 23, 24]])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0,  1,  2],\n",
                            "        [ 5,  6,  7],\n",
                            "        [10, 11, 12],\n",
                            "        [15, 16, 17],\n",
                            "        [20, 21, 22]])"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "l=torch.arange(25).reshape(5,-1)\n",
                "print(l)\n",
                "l[:,0:3]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Number of unique items and the size of each embedding vector\n",
                "num_items = 10  # Assume we have 10 unique items\n",
                "embedding_dim = 4  # Each item will be represented as a 4-dimensional vector\n",
                "\n",
                "# Define the embedding layer\n",
                "w=torch.randn([num_items, embedding_dim])\n",
                "w\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Model(torch.nn.Module):\n",
                "    def __init__(self):\n",
                "        super(Model,self).__init__()\n",
                "        self.l=torch.nn.Linear(5,6)\n",
                "        self.w=torch.nn.Parameter(\n",
                "            torch.ones([3,6])\n",
                "        )\n",
                "    def forward(self,x):\n",
                "        x=self.l(x)\n",
                "        x=self.w.matmul(x)\n",
                "        return x\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([3, 6])\n",
                        "torch.Size([6, 5])\n",
                        "torch.Size([6])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([-0.1346, -0.1346, -0.1346], grad_fn=<MvBackward0>)"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model=Model()\n",
                "for p in model.parameters():\n",
                "    print(p.shape)\n",
                "model(torch.rand(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.4949,  0.2817, -0.0755,  0.4635],\n",
                            "        [-0.2632,  0.1586, -0.3282, -0.2517],\n",
                            "        [-0.0466,  0.0246,  0.1128,  0.2269],\n",
                            "        [ 0.4029,  0.1313, -0.0139,  0.0515],\n",
                            "        [-0.3996, -0.3556, -0.1169,  0.2630],\n",
                            "        [-0.2006,  0.3181,  0.1958, -0.2306],\n",
                            "        [-0.2965,  0.0233, -0.3822,  0.1961],\n",
                            "        [-0.1119,  0.3873, -0.1108, -0.0181],\n",
                            "        [-0.3743, -0.3277, -0.4429,  0.4875],\n",
                            "        [ 0.1949,  0.3815, -0.3666,  0.3399]])"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nn.init.kaiming_uniform_(w, a=torch.math.sqrt(5))\n",
                "w"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "embedding_layer = nn.Embedding(num_items, embedding_dim,_weight=w)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([0.3774, 0.9605, 0.5294, 0.7933, 0.0470, 0.5367, 0.1014, 0.7028])\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "tensor([0.7547, 1.9210, 1.0588, 1.5865, 0.0000, 1.0734, 0.0000, 1.4056])"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a=torch.rand(8)\n",
                "print(a)\n",
                "dp = nn.Dropout(0.5)\n",
                "dp(a)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([-0.0745,  0.6489,  0.0623, -0.5137])"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "w[5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Item IDs: tensor([2, 5, 7])\n",
                        "Corresponding Embeddings:\n",
                        " tensor([[ 0.9213, -2.3571, -0.0884,  0.1023],\n",
                        "        [-0.0745,  0.6489,  0.0623, -0.5137],\n",
                        "        [ 1.1842,  0.6372,  1.7921, -0.7124]], grad_fn=<EmbeddingBackward0>)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Example item IDs (e.g., items bought by a user)\n",
                "item_ids = torch.tensor([2, 5, 7], dtype=torch.long)\n",
                "\n",
                "# Get the embeddings for the given item IDs\n",
                "item_embeddings = embedding_layer(item_ids)\n",
                "\n",
                "print(\"Item IDs:\", item_ids)\n",
                "print(\"Corresponding Embeddings:\\n\", item_embeddings)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.4507, -1.4142, -0.7936,  1.3749],\n",
                            "        [-1.3862,  0.7112, -0.6170, -0.4011],\n",
                            "        [ 0.9355,  0.7030,  1.4105, -0.9739]],\n",
                            "       grad_fn=<NativeBatchNormBackward0>)"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bn=nn.BatchNorm1d(embedding_dim)\n",
                "out:torch.Tensor=bn(item_embeddings)\n",
                "out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[ 0.6865,  0.4370,  0.7290, -0.1278],\n",
                            "        [ 0.7275, -1.3833, -1.4140,  1.2836],\n",
                            "        [-1.4140,  0.9463,  0.6850, -1.1558]],\n",
                            "       grad_fn=<NativeBatchNormBackward0>)"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bn(torch.randn(3, embedding_dim))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cuda_12_4",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
